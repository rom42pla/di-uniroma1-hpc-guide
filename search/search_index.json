{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome!","text":"<p>Welcome to the docs about the HPC at the Sapienza University of Rome!</p> <p>These docs are split in two, based on which kind of user are you:</p> <ul> <li> Admin section: head here if you're an admin;</li> <li> User section: head here if you want to know how to submit and monitor jobs on the cluster;</li> </ul>"},{"location":"#useful-links","title":"Useful links","text":"<ul> <li> Computer Science department website</li> </ul>"},{"location":"#contacts","title":"Contacts","text":"<ul> <li>Cluster admins: cluster.di@uniroma1.it</li> </ul>"},{"location":"admin_guide/","title":"Admin guide","text":"<p>TODO</p>"},{"location":"user_guide/","title":"User guide","text":"<ul> <li>How to connect to the cluster</li> <li>What is Slurm?</li> <li>How to use Slurm</li> </ul>"},{"location":"user_guide/how_to_connect_to_the_cluster/","title":"How to connect to the cluster","text":"<p>Connecting to the cluster involves several steps.</p> <ol> <li>Connect to the <code>frontend</code> server. You can do this using <code>ssh</code> to the address <code>151.100.174.45</code> which is accessible only through Sapienza network or its VPN:     <code>$ ssh &lt;user&gt;@151.100.174.45     &lt;user&gt;@151.100.174.45's password:</code>     Make sure to replace <code>&lt;user&gt;</code> with your username.      If you don't have one, ask an admin to create one for you.</li> <li>Once you're in the front-end node, you have to <code>ssh</code> again into the <code>submitter</code> node, from which you can use Slurm:     <code>$ ssh 192.168.0.2     &lt;user&gt;@192.168.0.2's password:</code>     Once there, you can use Slurm.</li> </ol>"},{"location":"user_guide/how_to_use_slurm/","title":"How to use Slurm","text":"<p>In this page we'll list some common Slurm interactions to run, cancel or monitor jobs.</p>"},{"location":"user_guide/how_to_use_slurm/#how-to-monitor-jobs","title":"How to monitor jobs","text":""},{"location":"user_guide/how_to_use_slurm/#monitor-the-status-of-clusters-nodes","title":"Monitor the status of cluster's nodes","text":"<p>The command <code>sinfo</code> can be used to monitor the state of each node, including partitions, time limits, state, and names of the nodes in that partition:</p> <pre><code>$ sinfo\nPARTITION AVAIL  TIMELIMIT  NODES  STATE NODELIST\nadmin        up   infinite      3   idle node[120-122]\ndebug        up   infinite     16   idle node[103-114,116,123-124,126]\nstudents*    up   infinite      0    n/a\n</code></pre> <p>For a full list of the meaning of each state, refer to Slurm's official docs. Some of the common states are:</p> <ul> <li><code>*</code>: the node is presently not responding and will not be allocated any new work;</li> <li><code>ALLOCATED</code>: the node has been allocated to one or more jobs;</li> <li>{<code>DOWN</code>, <code>DRAINED</code>, <code>FAIL</code>, <code>INVAL</code>}: the node is unavailable for use. Slurm can automatically place nodes in this state if some failure occurs, so inform an admin ASAP;</li> <li><code>DRAINING</code>: the node is currently allocated a job, but will not be allocated additional jobs;</li> <li>{<code>IDLE</code>, <code>MIXED</code>}: the node is not allocated to any jobs and is available for use;</li> <li><code>UNKNOWN</code>: the Slurm controller has just started and the node's state has not yet been determined.</li> </ul>"},{"location":"user_guide/how_to_use_slurm/#monitor-the-state-of-jobs","title":"Monitor the state of jobs","text":"<p>The command <code>squeue</code> can be used to view information about jobs located in the Slurm scheduling queue, including job ID, partition, name, user, state, execution time, node name:</p> <pre><code>$ squeue\nJOBID   PARTITION   NAME    USER    ST  TIME    NODES   NODELIST(REASON)\n326     debug       sleep   guest   R   0:03    1       node123\n</code></pre> <p>The <code>ST</code> column shows the states of the jobs. For a full list of the meaning of each state, refer to Slurm's official docs. Some of the common states are:</p> <ul> <li>{<code>BF</code>, <code>F</code>, <code>NF</code>, <code>PR</code>}: the job has failed to launch or complete;</li> <li><code>OOM</code>: the job experienced out of memory error;</li> <li><code>R</code>: the job is running; </li> <li><code>CG</code>: the job is in the process of completing. Some processes on some nodes may still be active.</li> </ul>"},{"location":"user_guide/how_to_use_slurm/#how-to-submit-jobs","title":"How to submit jobs","text":""},{"location":"user_guide/how_to_use_slurm/#how-to-submit-a-non-interactive-job","title":"How to submit a non-interactive job","text":"<p>A non-interactive job can be run using <code>srun &lt;commands&gt;</code>.  You have to remember to use the <code>-p</code> or <code>--partition</code> flag, alongside the requirements of the job.</p> <p>A job with no requirements can be run without further arguments:</p> <pre><code>$ srun -p &lt;partition&gt; bash -c \"echo 'It works! My name is:'; hostname\"\nIt works! My name is:\nnode116\n</code></pre> <p>A job with certain requirements needs all necessary resources to be specified: </p> <pre><code>srun -p &lt;partition&gt; --gpus=2 bash -c \"echo 'It works! Here is a summary of my GPUs:'; nvidia-smi\"\nIt works! Here is a brief of my GPUs:\nTue Mar 11 16:13:07 2025\n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 570.86.16              Driver Version: 570.86.16      CUDA Version: 12.8     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Quadro RTX 6000                Off |   00000000:41:00.0 Off |                    0 |\n| N/A   27C    P8             20W /  250W |       1MiB /  23040MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n|   1  Quadro RTX 6000                Off |   00000000:C1:00.0 Off |                    0 |\n| N/A   25C    P8             13W /  250W |       1MiB /  23040MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n\n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n|  No running processes found                                                             |\n+-----------------------------------------------------------------------------------------+\n</code></pre> <p>Read Slurm's official docs for a list of all the available flags.  Some common requirements are the following:</p> <ul> <li><code>--gpus</code>: the minimum number of GPUs the node must have to run the job;</li> <li><code>--mem</code>: the real memory required per node, in MBs;</li> </ul>"},{"location":"user_guide/how_to_use_slurm/#how-to-submit-a-non-interactive-container","title":"How to submit a non-interactive container","text":"<p>You can do it using Singularity. An interactive job can be run using <code>srun singularity run &lt;container_path&gt; &lt;commands&gt;</code>.</p> <p>In this example, the <code>hostname</code> command will be executed into the <code>pytorch</code> container run on a node:</p> <pre><code>$ srun singularity run docker://pytorch/pytorch:2.6.0-cuda12.6-cudnn9-devel hostname\nINFO:    Using cached SIF image\n\n==========\n== CUDA ==\n==========\n\nCUDA Version 12.6.3\n\nContainer image Copyright (c) 2016-2023, NVIDIA CORPORATION &amp; AFFILIATES. All rights reserved.\n\nThis container image and its contents are governed by the NVIDIA Deep Learning Container License.\nBy pulling and using the container, you accept the terms and conditions of this license:\nhttps://developer.nvidia.com/ngc/nvidia-deep-learning-container-license\n\nA copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.\n\nWARNING: The NVIDIA Driver was not detected.  GPU functionality will not be available.\n   Use the NVIDIA Container Toolkit to start this container with GPU support; see\n   https://docs.nvidia.com/datacenter/cloud-native/ .\n\nnode111\n</code></pre>"},{"location":"user_guide/how_to_use_slurm/#how-to-submit-an-interactive-container","title":"How to submit an interactive container","text":"<p>You can do it using Singularity. An interactive job can be run using <code>srun --pty singularity shell &lt;container_path&gt;</code>, where the <code>--pty</code> flag spawns a pseudo-terminal.</p> <p>In this example, the <code>pytorch</code> container will be executed on a node with 2 GPUs.  The <code>--nv</code> flag tells Singularity to mount the GPUs:</p> <pre><code>$ srun --gpus=2 --pty singularity shell --nv docker://pytorch/pytorch:2.6.0-cuda12.6-cudnn9-devel\nINFO:    Using cached SIF image\nSingularity&gt; nvidia-smi\nWed Mar 19 16:15:07 2025\n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 570.124.06             Driver Version: 570.124.06     CUDA Version: 12.8     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Quadro RTX 6000                Off |   00000000:41:00.0 Off |                    0 |\n| N/A   29C    P0             54W /  250W |       1MiB /  23040MiB |      3%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n|   1  Quadro RTX 6000                Off |   00000000:C1:00.0 Off |                    0 |\n| N/A   29C    P0             56W /  250W |       1MiB /  23040MiB |      4%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n\n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n|  No running processes found                                                             |\n+-----------------------------------------------------------------------------------------+\nSingularity&gt;\n</code></pre>"},{"location":"user_guide/how_to_use_slurm/#how-to-cancel-jobs","title":"How to cancel jobs","text":""},{"location":"user_guide/how_to_use_slurm/#cancel-a-job-by-its-job-id","title":"Cancel a job by its job ID","text":"<p>A particular job can be canceled using the <code>scancel &lt;job_id&gt;</code> command:</p> <pre><code>$ squeue\nJOBID   PARTITION   NAME    USER    ST  TIME    NODES   NODELIST(REASON)\n326     debug       sleep   debug   R   0:03    1       node123\n$ scancel 326\n$ squeue\nJOBID   PARTITION   NAME    USER    ST  TIME    NODES   NODELIST(REASON)\n326     debug       sleep   debug   CG   0:03    1       node123\n</code></pre>"},{"location":"user_guide/how_to_use_slurm/#cancel-all-the-jobs-of-a-user","title":"Cancel all the jobs of a user","text":"<p>All the jobs of a user can be canceled using the <code>-u</code> or <code>--user</code> flag, by typing <code>scancel --user &lt;user_id&gt;</code> command:</p> <pre><code>$ squeue\nJOBID   PARTITION   NAME    USER    ST  TIME    NODES   NODELIST(REASON)\n326     debug       sleep   debug   R   0:03    1       node123\n$ scancel --user debug\n$ squeue\nJOBID   PARTITION   NAME    USER    ST  TIME    NODES   NODELIST(REASON)\n326     debug       sleep   debug   CG   0:03    1       node123\n</code></pre>"},{"location":"user_guide/what_is_slurm/","title":"What is Slurm?","text":"<p>Slurm is a system that helps manage and run jobs on a group of computer nodes called a cluster.  It makes sure that the right jobs are running on the right computers at the right time.</p> <p></p> <p>Slurm has three main purposes:</p> <ul> <li>Allocates exclusive and/or non-exclusive access to resources (compute nodes) to users for some duration of time so they can perform work;</li> <li>Provides a framework for starting, executing, and monitoring work (normally a parallel job) on the set of allocated nodes;</li> <li>Arbitrates contention for resources by managing a queue of pending work;</li> </ul>"},{"location":"user_guide/what_is_slurm/#slurms-internal-structure","title":"Slurm's internal structure","text":"<p>Slurm consists of a set of daemons: - The <code>slurmctld</code> daemon, a centralized manager to monitor resources and work. There may also be a backup manager to assume those responsibilities in the event of failure; - The <code>slurmd</code> daemon running on each compute node, which provide fault-tolerant hierarchical communications and lets users interact with the cluster. Basically: it waits for work, executes that work, returns status, and waits for more work; - The optional <code>slurmdbd</code> daemon, which can be used to record accounting information for multiple Slurm-managed clusters in a single database; - The optional <code>slurmrestd</code> daemon which can be used to interact with Slurm through its REST API.</p>"},{"location":"user_guide/what_is_slurm/#slurm-commands","title":"Slurm commands","text":"<p>All Slurm commands start with <code>s</code>:</p> <ul> <li> <p><code>sacct</code> is used to report job or job step accounting information about active or completed jobs.</p> </li> <li> <p><code>salloc</code> is used to allocate resources for a job in real time. Typically this is used to allocate resources and spawn a shell. The shell is then used to execute srun commands to launch parallel tasks.</p> </li> <li> <p><code>sattach</code> is used to attach standard input, output, and error plus signal capabilities to a currently running job or job step. One can attach to and detach from jobs multiple times.</p> </li> <li> <p><code>sbatch</code> is used to submit a job script for later execution. The script will typically contain one or more srun commands to launch parallel tasks.</p> </li> <li> <p><code>sbcast</code> is used to transfer a file from local disk to local disk on the nodes allocated to a job. This can be used to effectively use diskless compute nodes or provide improved performance relative to a shared file system.</p> </li> <li> <p><code>scancel</code> is used to cancel a pending or running job or job step. It can also be used to send an arbitrary signal to all processes associated with a running job or job step.</p> </li> <li> <p><code>scontrol</code> is the administrative tool used to view and/or modify Slurm state. Note that many scontrol commands can only be executed as user root.</p> </li> <li> <p><code>sinfo</code> reports the state of partitions and nodes managed by Slurm. It has a wide variety of filtering, sorting, and formatting options.</p> </li> <li> <p><code>sprio</code> is used to display a detailed view of the components affecting a job's priority.</p> </li> <li> <p><code>squeue</code> reports the state of jobs or job steps. It has a wide variety of filtering, sorting, and formatting options. By default, it reports the running jobs in priority order and then the pending jobs in priority order.</p> </li> <li> <p><code>srun</code> is used to submit a job for execution or initiate job steps in real time. srun has a wide variety of options to specify resource requirements, including: minimum and maximum node count, processor count, specific nodes to use or not use, and specific node characteristics (so much memory, disk space, certain required features, etc.). A job can contain multiple job steps executing sequentially or in parallel on independent or shared resources within the job's node allocation.</p> </li> <li> <p><code>sshare</code> displays detailed information about fairshare usage on the cluster. Note that this is only viable when using the priority/multifactor plugin.</p> </li> <li> <p><code>sstat</code> is used to get information about the resources utilized by a running job or job step.</p> </li> <li> <p><code>strigger</code> is used to set, get or view event triggers. Event triggers include things such as nodes going down or jobs approaching their time limit.</p> </li> <li> <p><code>sview</code> is a graphical user interface to get and update state information for jobs, partitions, and nodes managed by Slurm.</p> </li> </ul>"}]}